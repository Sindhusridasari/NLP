{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/spam.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>label_in_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  label_in_num  \n",
       "0        NaN        NaN             0  \n",
       "1        NaN        NaN             0  \n",
       "2        NaN        NaN             1  \n",
       "3        NaN        NaN             0  \n",
       "4        NaN        NaN             0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.rename(columns={'Category':'v1','Message':'v2'})\n",
    "df['label_in_num']=df['v1'].map({'ham':0,'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  labels                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6    ham  Even my brother is not like to speak with me. ...\n",
       "7    ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.iloc[:,[0,1]]\n",
    "df.columns=['labels','text']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Frequency of Both labels ')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(df.labels)\n",
    "plt.title('Frequency of Both labels ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels  text                                                                                                                                    \n",
       "ham     Sorry, I'll call later                                                                                                                      30\n",
       "        I cant pick the phone right now. Pls send a message                                                                                         12\n",
       "        Ok...                                                                                                                                       10\n",
       "        Okie                                                                                                                                         4\n",
       "        Ok.                                                                                                                                          4\n",
       "                                                                                                                                                    ..\n",
       "        I forgot 2 ask Ì_ all smth.. There's a card on da present lei... How? ÌÏ all want 2 write smth or sign on it?                                1\n",
       "        I get out of class in bsn in like  &lt;#&gt;  minutes, you know where advising is?                                                           1\n",
       "        I got another job! The one at the hospital doing data analysis or something, starts on monday! Not sure when my thesis will got finished     1\n",
       "        I got arrested for possession at, I shit you not,  &lt;TIME&gt;  pm                                                                          1\n",
       "        ÌÏ wait 4 me in sch i finish ard 5..                                                                                                         1\n",
       "Length: 4516, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['labels']=='ham'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       Go until jurong point, crazy.. Available only ...\n",
       " 1                           Ok lar... Joking wif u oni...\n",
       " 2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       " 3       U dun say so early hor... U c already then say...\n",
       " 4       Nah I don't think he goes to usf, he lives aro...\n",
       "                               ...                        \n",
       " 5567    This is the 2nd time we have tried 2 contact u...\n",
       " 5568                Will Ì_ b going to esplanade fr home?\n",
       " 5569    Pity, * was in mood for that. So...any other s...\n",
       " 5570    The guy did some bitching but I acted like i'd...\n",
       " 5571                           Rofl. Its true to its name\n",
       " Name: text, Length: 5572, dtype: object,\n",
       " 0        ham\n",
       " 1        ham\n",
       " 2       spam\n",
       " 3        ham\n",
       " 4        ham\n",
       "         ... \n",
       " 5567    spam\n",
       " 5568     ham\n",
       " 5569     ham\n",
       " 5570     ham\n",
       " 5571     ham\n",
       " Name: labels, Length: 5572, dtype: object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df['text']\n",
    "Y=df.labels\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=Y.reshape(-1,1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords   #remove stopwords\n",
    "from nltk.stem.porter import PorterStemmer   #stemming\n",
    "import re\n",
    "#Different models for converting text to vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer #BOW\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem=PorterStemmer()\n",
    "corpus=[]\n",
    "for i in range(len(df['text'])):\n",
    "    text_1=re.sub('[^a-zA-Z]',\" \",df['text'][i])\n",
    "    text_1=text_1.lower()\n",
    "    text_1=text_1.split()\n",
    "    text_1=[port_stem.stem(word) for word in text_1 if word not in stopwords.words('english')]\n",
    "    text_1=' '.join(text_1)\n",
    "    corpus.append(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5572)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus),len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xval,ytrain,yval=train_test_split(corpus,Y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 4457, 1115, 1115)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),len(ytrain),len(xval),len(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[text.split() for text in xtrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raju\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\gensim\\models\\base_any2vec.py:742: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "w2v_model = gensim.models.Word2Vec(size=300, window=3,min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 1339\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928233, 1279456)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(docs,total_examples=len(docs),epochs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 5538\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(xtrain)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(xtrain), maxlen=300)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(xval), maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  997,   15,  404],\n",
       "       [   0,    0,    0, ...,  122, 1600,   62],\n",
       "       [   0,    0,    0, ..., 2000,   88,  998],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  354,    6,    8],\n",
       "       [   0,    0,    0, ...,    0,    0,  903],\n",
       "       [   0,    0,    0, ...,    3, 1664, 2862]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(5538, 300)\n"
     ]
    }
   ],
   "source": [
    "len(x_train),len(ytrain),len(x_test),len(yval)\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "print(embedding_matrix)\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.04660127, -0.23579474,  0.13505618, ..., -0.55608195,\n",
       "        -0.19572303,  0.46280655],\n",
       "       [-0.0373338 , -0.01621343,  0.14874673, ..., -0.08717895,\n",
       "         0.33774507,  0.17923035],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense, Dropout, Embedding\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=300, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 300, 300)          1661400   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300, 300)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,754,905\n",
      "Trainable params: 93,505\n",
      "Non-trainable params: 1,661,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "# Build The model\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9723WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 112s 850ms/step - loss: 0.1074 - accuracy: 0.9723 - val_loss: 0.0692 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9816WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 107s 853ms/step - loss: 0.0577 - accuracy: 0.9816 - val_loss: 0.0758 - val_accuracy: 0.9821 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9845WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 103s 818ms/step - loss: 0.0514 - accuracy: 0.9845 - val_loss: 0.0655 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9835WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 103s 815ms/step - loss: 0.0485 - accuracy: 0.9835 - val_loss: 0.0670 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0426 - accuracy: 0.9875WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 107s 849ms/step - loss: 0.0426 - accuracy: 0.9875 - val_loss: 0.0705 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9885WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 103s 815ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0674 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9885WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 107s 852ms/step - loss: 0.0390 - accuracy: 0.9885 - val_loss: 0.0677 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9893WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 110s 872ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.0751 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9920WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 105s 833ms/step - loss: 0.0282 - accuracy: 0.9920 - val_loss: 0.0705 - val_accuracy: 0.9843 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9915WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "126/126 [==============================] - 108s 852ms/step - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.0727 - val_accuracy: 0.9865 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]\n",
    "\n",
    "history = model.fit(x_train, ytrain,batch_size=32,epochs=10,validation_split=0.1,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 4s 101ms/step - loss: 0.0727 - accuracy: 0.9812\n",
      "\n",
      "ACCURACY: 0.9811659455299377\n",
      "LOSS: 0.07265845686197281\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, yval, batch_size=32)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "259b7988676334e1eced82b9176981ede4374192af6b955b743b2a86d4657d68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
